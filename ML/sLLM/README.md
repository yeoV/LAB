# ML repo

#### sLLM

- DPO training with LoRA
  - LoRA 방식을 활용한 DPO 트레이닝 코드
  - ML/sLLM/dpo_trainer_with_lora.ipynb

##### Quantization 에 대한 것

모델의 크기 감소, 메모리 사용량 감소, 추론 속도 향상
내 생각들.

- INT 4 Bit 양자화는 어떻게 가능할까? int 는 보통 32 비트 아닌가?
  - Q : 여기서 4,8 비트가 의미하는 건 데이터를 저장할 떄 사용하는 비트의 수를 의미.
        예를 들어, Int 타입의 4 비트라면, 0~15 까지의 숫자 표현이 가능함
  - Q : Int 와 Float 형의 차이점?
    - 주로 카운트, 인덱싱, 단순한 숫자 계산 등 단순한 연산에 Int 형 사용
    - Float 형은 보통 16 비트를 사용함 -> 부동 소수점 표현으로 16 비트 만큼의 크기를 사용함 -> 보통 지수부, 가수부로 나누어져 있어 4비트로는 표현에 제한이 있음
